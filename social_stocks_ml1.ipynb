{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c972e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from config import password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9640e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614b784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(f'postgresql://postgres:{password}@stock-sentiment.cx2wqgu4uxsm.us-east-1.rds.amazonaws.com:5432/Stockdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474da3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5031762, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = pd.read_sql('select * from comments_posts', con=engine)\n",
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55885d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>It‚Äôs great that so much has been donated. but ...</td>\n",
       "      <td>Vertigo_uk123</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>speaking of amc, I bought amc@$20 and bbby@$46...</td>\n",
       "      <td>pixlbabble</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>go BBBY!</td>\n",
       "      <td>Buy_Sell_Buy_Sell_</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>I‚Äôm proud of you BBBYüë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®</td>\n",
       "      <td>wiskw76</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>$AMC &amp;amp; $BBBY ready for lift off</td>\n",
       "      <td>kerplunktard</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               body  \\\n",
       "0  2021-03-15  It‚Äôs great that so much has been donated. but ...   \n",
       "1  2021-03-15  speaking of amc, I bought amc@$20 and bbby@$46...   \n",
       "2  2021-03-15                                           go BBBY!   \n",
       "3  2021-03-15                      I‚Äôm proud of you BBBYüë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®   \n",
       "4  2021-03-15                $AMC &amp; $BBBY ready for lift off   \n",
       "\n",
       "             username       subreddit  \n",
       "0       Vertigo_uk123  wallstreetbets  \n",
       "1          pixlbabble  wallstreetbets  \n",
       "2  Buy_Sell_Buy_Sell_  wallstreetbets  \n",
       "3             wiskw76  wallstreetbets  \n",
       "4        kerplunktard  wallstreetbets  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2309f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"date\", \"body\", \"username\", \"subreddit\",\n",
    "   ]\n",
    "\n",
    "target = [\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5a9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "comments_df = comments_df.drop([\"username\",\"subreddit\"],axis=1)\n",
    "# Create our target\n",
    "y = comments_df.loc[:, target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9230c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'body', 'username'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9510146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5031762, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "401f2335",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 15.5 TiB for an array with shape (4130837, 4130837) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32836/1714008201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    941\u001b[0m                 \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 943\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    944\u001b[0m             )\n\u001b[0;32m    945\u001b[0m             \u001b[0mwith_dummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;31m# take on axis=1 + transpose to ensure ndarray layout is column-major\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m         \u001b[0mdummy_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\lib\\twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[1;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 15.5 TiB for an array with shape (4130837, 4130837) and data type uint8"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc47e1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5010158</td>\n",
       "      <td>5031762</td>\n",
       "      <td>5010158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1381</td>\n",
       "      <td>4130837</td>\n",
       "      <td>428286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>GME</td>\n",
       "      <td>freehouse_throwaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>64429</td>\n",
       "      <td>3479</td>\n",
       "      <td>11602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date     body             username\n",
       "count      5010158  5031762              5010158\n",
       "unique        1381  4130837               428286\n",
       "top     2021-01-28      GME  freehouse_throwaway\n",
       "freq         64429     3479                11602"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd25f343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GME                                                                                                                                                                                                                                                                                                                         3479\n",
       "BB                                                                                                                                                                                                                                                                                                                          2820\n",
       "PLTR                                                                                                                                                                                                                                                                                                                        2517\n",
       "TSLA                                                                                                                                                                                                                                                                                                                        2336\n",
       "AMC                                                                                                                                                                                                                                                                                                                         2253\n",
       "                                                                                                                                                                                                                                                                                                                            ... \n",
       "Fractional shares and GME                                                                                                                                                                                                                                                                                                      1\n",
       "GME RIDE OR DIE                                                                                                                                                                                                                                                                                                                1\n",
       "If you are not into GME positions and you really wanna yolo things tomorrow, look at other tickers instead, remember, don't bet money you are not willing to lose                                                                                                                                                              1\n",
       "Yeah, I think it'll be ok. I think the dust is going to settle, the people who lost money on GME buying at the top are gonna head over to other subs (like r/ClassActionRobinHood/), this sub should hopefully return to normal (whatever \"normal\" means here, this has always been a weird sub) within a couple months.       1\n",
       "BBBY anybody?                                                                                                                                                                                                                                                                                                                  1\n",
       "Name: body, Length: 4130837, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y['body'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9dc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "comments_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed3ec457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036400d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739018bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60394720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a65832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b33ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6787b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521afc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2efe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f13068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "brf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bf3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = brf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686fc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = brf.feature_importances_\n",
    "cols = X.columns\n",
    "feature_importances_df = pd.DataFrame({'feature':cols, 'importance': importances})\n",
    "feature_importances_df.head()\n",
    "feature_importances_df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec = EasyEnsembleClassifier(n_estimators=100, random_state=1)\n",
    "eec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = eec.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df216b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "comment_counts = comment_df[\"body\"].value_counts()\n",
    "print(len(comment_counts))\n",
    "comment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the value counts of comments\n",
    "comment_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc11411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "#replace_application = list(application_counts[application_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "#for app in replace_application:\n",
    "    #application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "comments_df.body.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4585a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_counts = comments_df.CLASSIFICATION.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d874a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the value counts of CLASSIFICATION\n",
    "class_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79da535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists\n",
    "comments_cat = comments_df.dtypes[comments_df.dtypes == \"object\"].index.tolist()\n",
    "comments_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e922b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(comments_df[comments_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(comments_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4453b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "comments_df = comments_df.merge(encode_df,left_index=True, right_index=True)\n",
    "comments_df = comments_df.drop(comments_cat,1)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e99638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = comments_df[\"Positive\"].values\n",
    "X = comments_df.drop([\"Negative\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6794b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  80\n",
    "hidden_nodes_layer2 = 30\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208606af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c972e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "# from config import password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9640e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474da3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>overall_sent_comp</th>\n",
       "      <th>overall_sent_pos</th>\n",
       "      <th>overall_sent_neg</th>\n",
       "      <th>mean_t_comp_score</th>\n",
       "      <th>mean_t_pos_score</th>\n",
       "      <th>mean_t_neg_score</th>\n",
       "      <th>mean_tgt_comp_score</th>\n",
       "      <th>mean_tgt_pos_score</th>\n",
       "      <th>mean_tgt_neg_score</th>\n",
       "      <th>verb_tense</th>\n",
       "      <th>mean_custom_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007445</td>\n",
       "      <td>DIS</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Hubers57</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Pretty uncommon to find a 100%+ iv stock like ...</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.08706666666666667</td>\n",
       "      <td>0.11783333333333333</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>-0.5818</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.157</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007451</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>duathman</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Haha.  If we keep swinging down it will wipe m...</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.009333333333333324</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.10533333333333333</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.316</td>\n",
       "      <td>future</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007456</td>\n",
       "      <td>TA</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>sc0tt_1990</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Here''s what will happen: NCAA is rallying the...</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0</td>\n",
       "      <td>0.18462</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007469</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>smallstreetgains</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>**Subreddit:** /r/wallstreetbets\\n\\n**Searched...</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007469</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>smallstreetgains</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>**Subreddit:** /r/wallstreetbets\\n\\n**Searched...</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id ticker        date          username       subreddit  \\\n",
       "0    1007445    DIS  2020-08-11          Hubers57  wallstreetbets   \n",
       "1    1007451   MSFT  2020-08-11          duathman  wallstreetbets   \n",
       "2    1007456     TA  2020-08-10        sc0tt_1990  wallstreetbets   \n",
       "3    1007469   TSLA  2020-08-10  smallstreetgains  wallstreetbets   \n",
       "4    1007469   AAPL  2020-08-10  smallstreetgains  wallstreetbets   \n",
       "\n",
       "                                                body overall_sent_comp  \\\n",
       "0  Pretty uncommon to find a 100%+ iv stock like ...            0.5078   \n",
       "1  Haha.  If we keep swinging down it will wipe m...           -0.4215   \n",
       "2  Here''s what will happen: NCAA is rallying the...            0.9231   \n",
       "3  **Subreddit:** /r/wallstreetbets\\n\\n**Searched...            0.1779   \n",
       "4  **Subreddit:** /r/wallstreetbets\\n\\n**Searched...            0.1779   \n",
       "\n",
       "  overall_sent_pos overall_sent_neg     mean_t_comp_score  \\\n",
       "0            0.102            0.075   0.08706666666666667   \n",
       "1            0.167            0.203  0.009333333333333324   \n",
       "2            0.154                0               0.18462   \n",
       "3            0.022            0.013   0.03119999999999999   \n",
       "4            0.022            0.013   0.03119999999999999   \n",
       "\n",
       "      mean_t_pos_score     mean_t_neg_score mean_tgt_comp_score  \\\n",
       "0  0.11783333333333333               0.0485             -0.5818   \n",
       "1                 0.42  0.10533333333333333             -0.8126   \n",
       "2                0.059                    0              0.9231   \n",
       "3                0.006              0.08775              0.5267   \n",
       "4                0.006              0.08775              0.5267   \n",
       "\n",
       "  mean_tgt_pos_score mean_tgt_neg_score verb_tense    mean_custom_score  \n",
       "0              0.084              0.157    present                    0  \n",
       "1              0.082              0.316     future                   -1  \n",
       "2              0.295                  0    present                   -1  \n",
       "3              0.024                  0    present  0.14285714285714285  \n",
       "4              0.024                  0    present  0.14285714285714285  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_data_to_load = \"twitter.csv\"\n",
    "sentiments_df = pd.read_csv(sentiments_data_to_load, low_memory=False)\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c135688e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BA                                                                                                                                                                                                                        24339\n",
       "SPCE                                                                                                                                                                                                                      23462\n",
       "RE                                                                                                                                                                                                                        16773\n",
       "TIL                                                                                                                                                                                                                       14092\n",
       "MSFT                                                                                                                                                                                                                       4957\n",
       "AMD                                                                                                                                                                                                                        4892\n",
       "AAPL                                                                                                                                                                                                                       4611\n",
       "AMZN                                                                                                                                                                                                                       4186\n",
       "FB                                                                                                                                                                                                                         4063\n",
       "DIS                                                                                                                                                                                                                        3999\n",
       "NVDA                                                                                                                                                                                                                       3952\n",
       "DOW                                                                                                                                                                                                                        3758\n",
       "NFLX                                                                                                                                                                                                                       3643\n",
       "GOOG                                                                                                                                                                                                                       3439\n",
       "TSLA                                                                                                                                                                                                                       2820\n",
       "SQ                                                                                                                                                                                                                         1155\n",
       "BABA                                                                                                                                                                                                                        764\n",
       "TD                                                                                                                                                                                                                          272\n",
       "AI                                                                                                                                                                                                                          167\n",
       "TA                                                                                                                                                                                                                          131\n",
       " UUP 3/27 $28c DAL 4/17 $35c                                                                                                                                                                                                  2\n",
       " and He needs money! He always needs money! He''s all-powerful                                                                                                                                                                1\n",
       " it might be a REALLY good idea to get into long dated (around September) calls now on these 5G companies to try and make an earnings report play early. Their profit might be down (with the exception of maybe QCOM)        1\n",
       " re-sold                                                                                                                                                                                                                      1\n",
       " I personally think Short Interest today is higher than whatever number we see on the '\"Short Report'\" this evening.  Of course I could be wrong and Short Interest is lower                                                  1\n",
       " then you would be on the hook for all of your gains and your adjusted cost-basis would carry forward into the NEXT year                                                                                                      1\n",
       " could not have come at a worse time for AMD. They finally after 10 years have top tier tech inside the datacenter                                                                                                            1\n",
       " IG is profit sharing with content creators                                                                                                                                                                                   1\n",
       " from $1k to currently about $1                                                                                                                                                                                               1\n",
       "Name: ticker, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_df['ticker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68940d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list = [\"BA\",\"SPCE\",\"TIL\",\"MSFT\",\"AMD\",\"AAPL\",\"AMZN\",\"FB\",\"DIS\",\"NVDA\",\"NFLX\",\"GOOG\",\"TSLA\",\"SQ\",\"BABA\",\"TD\",\"AI\",\"TA\"]\n",
    "ticker_list = [\"MSFT\",\"AAPL\",\"AMZN\",\"FB\",\"GOOG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325c66aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>overall_sent_comp</th>\n",
       "      <th>overall_sent_pos</th>\n",
       "      <th>overall_sent_neg</th>\n",
       "      <th>mean_t_comp_score</th>\n",
       "      <th>mean_t_pos_score</th>\n",
       "      <th>mean_t_neg_score</th>\n",
       "      <th>mean_tgt_comp_score</th>\n",
       "      <th>mean_tgt_pos_score</th>\n",
       "      <th>mean_tgt_neg_score</th>\n",
       "      <th>verb_tense</th>\n",
       "      <th>mean_custom_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007451</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>duathman</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Haha.  If we keep swinging down it will wipe m...</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.009333333333333324</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.10533333333333333</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.316</td>\n",
       "      <td>future</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007469</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>smallstreetgains</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>**Subreddit:** /r/wallstreetbets\\n\\n**Searched...</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1007469</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>smallstreetgains</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>**Subreddit:** /r/wallstreetbets\\n\\n**Searched...</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1007469</td>\n",
       "      <td>FB</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>smallstreetgains</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>**Subreddit:** /r/wallstreetbets\\n\\n**Searched...</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0.14285714285714285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1007492</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>captain_blabbin</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Just grabbed a couple FB Jan 15 ''21 280c''s ....</td>\n",
       "      <td>-0.6872</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.3436</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>-0.6872</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.259</td>\n",
       "      <td>present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id ticker        date          username       subreddit  \\\n",
       "1     1007451   MSFT  2020-08-11          duathman  wallstreetbets   \n",
       "4     1007469   AAPL  2020-08-10  smallstreetgains  wallstreetbets   \n",
       "6     1007469   MSFT  2020-08-10  smallstreetgains  wallstreetbets   \n",
       "7     1007469     FB  2020-08-10  smallstreetgains  wallstreetbets   \n",
       "12    1007492   AMZN  2020-08-10   captain_blabbin  wallstreetbets   \n",
       "\n",
       "                                                 body overall_sent_comp  \\\n",
       "1   Haha.  If we keep swinging down it will wipe m...           -0.4215   \n",
       "4   **Subreddit:** /r/wallstreetbets\\n\\n**Searched...            0.1779   \n",
       "6   **Subreddit:** /r/wallstreetbets\\n\\n**Searched...            0.1779   \n",
       "7   **Subreddit:** /r/wallstreetbets\\n\\n**Searched...            0.1779   \n",
       "12  Just grabbed a couple FB Jan 15 ''21 280c''s ....           -0.6872   \n",
       "\n",
       "   overall_sent_pos overall_sent_neg     mean_t_comp_score mean_t_pos_score  \\\n",
       "1             0.167            0.203  0.009333333333333324             0.42   \n",
       "4             0.022            0.013   0.03119999999999999            0.006   \n",
       "6             0.022            0.013   0.03119999999999999            0.006   \n",
       "7             0.022            0.013   0.03119999999999999            0.006   \n",
       "12            0.043            0.124               -0.3436            0.045   \n",
       "\n",
       "       mean_t_neg_score mean_tgt_comp_score mean_tgt_pos_score  \\\n",
       "1   0.10533333333333333             -0.8126              0.082   \n",
       "4               0.08775              0.5267              0.024   \n",
       "6               0.08775              0.5267              0.024   \n",
       "7               0.08775              0.5267              0.024   \n",
       "12               0.1295             -0.6872               0.09   \n",
       "\n",
       "   mean_tgt_neg_score verb_tense    mean_custom_score  \n",
       "1               0.316     future                   -1  \n",
       "4                   0    present  0.14285714285714285  \n",
       "6                   0    present  0.14285714285714285  \n",
       "7                   0    present  0.14285714285714285  \n",
       "12              0.259    present                    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentiments_df = sentiments_df.loc[sentiments_df[\"ticker\"].isin (ticker_list)]\n",
    "\n",
    "cleaned_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec80d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21256, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentiments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b46701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21256, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentiments_df = cleaned_sentiments_df.drop(columns=[\"comment_id\",\"date\",\"username\",\"subreddit\",\"body\",\"verb_tense\"])\n",
    "\n",
    "final_sentiments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77fd47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentiments_df.to_csv(\"final_twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cc63c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21256, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_sentiments_df.drop(columns=[\"mean_custom_score\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5a9a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21256, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = final_sentiments_df.loc[:, [\"mean_custom_score\"]].copy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd25f343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSFT    4957\n",
       "AAPL    4611\n",
       "AMZN    4186\n",
       "FB      4063\n",
       "GOOG    3439\n",
       "Name: ticker, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "X['ticker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79142ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_feature(array):\n",
    "    \"\"\" Encode a categorical array into a number array\n",
    "    \n",
    "    :param array: array to be encoded\n",
    "    :return: numerical array\n",
    "    \"\"\"\n",
    "  \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(array)\n",
    "    return encoder.transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f2190d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"ticker\"] = encode_feature(X[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5434ebe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    4957\n",
       "0    4611\n",
       "1    4186\n",
       "2    4063\n",
       "3    3439\n",
       "Name: ticker, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['ticker'].value_counts()\n",
    "\n",
    "# MSFT    4\n",
    "# AAPL    0\n",
    "# AMZN    1\n",
    "# FB      2\n",
    "# GOOG    3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2ef7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>overall_sent_comp</th>\n",
       "      <th>overall_sent_pos</th>\n",
       "      <th>overall_sent_neg</th>\n",
       "      <th>mean_t_comp_score</th>\n",
       "      <th>mean_t_pos_score</th>\n",
       "      <th>mean_t_neg_score</th>\n",
       "      <th>mean_tgt_comp_score</th>\n",
       "      <th>mean_tgt_pos_score</th>\n",
       "      <th>mean_tgt_neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.009333333333333324</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.10533333333333333</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.03119999999999999</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.08775</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.6872</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.3436</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>-0.6872</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker overall_sent_comp overall_sent_pos overall_sent_neg  \\\n",
       "1        4           -0.4215            0.167            0.203   \n",
       "4        0            0.1779            0.022            0.013   \n",
       "6        4            0.1779            0.022            0.013   \n",
       "7        2            0.1779            0.022            0.013   \n",
       "12       1           -0.6872            0.043            0.124   \n",
       "\n",
       "       mean_t_comp_score mean_t_pos_score     mean_t_neg_score  \\\n",
       "1   0.009333333333333324             0.42  0.10533333333333333   \n",
       "4    0.03119999999999999            0.006              0.08775   \n",
       "6    0.03119999999999999            0.006              0.08775   \n",
       "7    0.03119999999999999            0.006              0.08775   \n",
       "12               -0.3436            0.045               0.1295   \n",
       "\n",
       "   mean_tgt_comp_score mean_tgt_pos_score mean_tgt_neg_score  \n",
       "1              -0.8126              0.082              0.316  \n",
       "4               0.5267              0.024                  0  \n",
       "6               0.5267              0.024                  0  \n",
       "7               0.5267              0.024                  0  \n",
       "12             -0.6872               0.09              0.259  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3ec457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03a0496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'mean_custom_score': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "976c3556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "036400d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3625643157469876"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1f3cd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "           0,    2,    0,    0,    3,    1,    0,    0,    0,    0,    1,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    4,    1,    0,    0,    1,    1,    3,    3,    0,    3,\n",
       "           0,    0,    1,    3,    0,    1,    0,    0,    0,    0,    0,\n",
       "           1,    3,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    1,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    7,   10,    3,    9,    0,    3,    1,   10,    0,   11,\n",
       "           9,    6,    1,    4,    0,    3,    2,    1,    2,    0,    1,\n",
       "           0,   10,    4,    3,    0],\n",
       "       [  10,   23,   30,    0,   46,    5,   19,   34,   92,    6,   59,\n",
       "          13,   23,   10,   31,   24,   50,   28,    4,    0,   10,    9,\n",
       "           4,   43,    9,   34,   79],\n",
       "       [   0,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   10,    0,    0,    7,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    1,    0,    0,    2,    0,    0,    2,    0,    0,    1,\n",
       "           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    1,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    3,    0,    0,    2,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    1,    2,    0,    2,    0,    0,    1,    3,    0,    3,\n",
       "           1,    2,    1,    4,    0,    3,    2,    0,    1,   10,    0,\n",
       "          57,    4,    1,    0,   19],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    3,    0,    1,    0,    1,    2,    2,    0,    2,\n",
       "           0,    3,    0,    1,    0,    8,    1,    0,    0,    0,    8,\n",
       "          10,    0,    6,    0,   18],\n",
       "       [   0,    0,    0,    0,    1,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           5,    1,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,    0],\n",
       "       [  10,   14,   40,    0,   19,    4,    9,   15,   53,    3,   31,\n",
       "          18,   31,    2,   14,  132,   22,   13,   45,   17,  158,  112,\n",
       "        1565,   39,   35,   17, 1830]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "739018bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "-0.14285714285714285       0.04      1.00      1.00      0.08      1.00      1.00         1\n",
      "-0.16666666666666666       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                -0.2       0.00      0.00      0.98      0.00      0.00      0.00         9\n",
      "               -0.25       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " -0.3333333333333333       0.00      0.00      0.98      0.00      0.00      0.00        26\n",
      "-0.33333333333333337       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "-0.42857142857142855       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                -0.5       0.00      0.00      0.99      0.00      0.00      0.00         3\n",
      "                -0.6       0.00      0.00      0.97      0.00      0.00      0.00         1\n",
      " -0.6666666666666666       0.10      1.00      1.00      0.18      1.00      1.00         1\n",
      "                  -1       0.10      0.11      0.98      0.10      0.33      0.10       101\n",
      "                   0       0.31      0.02      0.99      0.04      0.14      0.02       695\n",
      " 0.14285714285714285       0.12      0.50      0.99      0.20      0.70      0.47        20\n",
      " 0.16666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "                 0.2       0.00      0.00      0.99      0.00      0.00      0.00         9\n",
      "                0.25       0.01      0.33      0.97      0.02      0.57      0.30         6\n",
      "  0.3333333333333333       0.03      0.03      0.98      0.03      0.16      0.02       117\n",
      " 0.33333333333333337       0.02      1.00      0.99      0.04      1.00      0.99         1\n",
      " 0.41666666666666663       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      " 0.42857142857142855       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " 0.45454545454545453       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "                 0.5       0.06      0.12      0.98      0.08      0.34      0.11        66\n",
      "                 0.6       0.00      0.62      0.69      0.01      0.66      0.43         8\n",
      "  0.6666666666666666       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "  0.7142857142857143       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                0.75       0.04      1.00      0.99      0.07      0.99      0.99         2\n",
      "                   1       0.94      0.43      0.89      0.59      0.62      0.37      4248\n",
      "\n",
      "         avg / total       0.80      0.36      0.91      0.48      0.53      0.30      5314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60394720",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21820/918486900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Resample the training data with SMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    734\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m             )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa4d57fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd8f96e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3625643157469876"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccadf0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "           0,    2,    0,    0,    3,    1,    0,    0,    0,    0,    1,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    4,    1,    0,    0,    1,    1,    3,    3,    0,    3,\n",
       "           0,    0,    1,    3,    0,    1,    0,    0,    0,    0,    0,\n",
       "           1,    3,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    1,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    7,   10,    3,    9,    0,    3,    1,   10,    0,   11,\n",
       "           9,    6,    1,    4,    0,    3,    2,    1,    2,    0,    1,\n",
       "           0,   10,    4,    3,    0],\n",
       "       [  10,   23,   30,    0,   46,    5,   19,   34,   92,    6,   59,\n",
       "          13,   23,   10,   31,   24,   50,   28,    4,    0,   10,    9,\n",
       "           4,   43,    9,   34,   79],\n",
       "       [   0,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,   10,    0,    0,    7,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    1,    0,    0,    2,    0,    0,    2,    0,    0,    1,\n",
       "           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    1,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    3,    0,    0,    2,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    1,    2,    0,    2,    0,    0,    1,    3,    0,    3,\n",
       "           1,    2,    1,    4,    0,    3,    2,    0,    1,   10,    0,\n",
       "          57,    4,    1,    0,   19],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    3,    0,    1,    0,    1,    2,    2,    0,    2,\n",
       "           0,    3,    0,    1,    0,    8,    1,    0,    0,    0,    8,\n",
       "          10,    0,    6,    0,   18],\n",
       "       [   0,    0,    0,    0,    1,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           5,    1,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,    0],\n",
       "       [  10,   14,   40,    0,   19,    4,    9,   15,   53,    3,   31,\n",
       "          18,   31,    2,   14,  132,   22,   13,   45,   17,  158,  112,\n",
       "        1565,   39,   35,   17, 1830]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4a65832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "-0.14285714285714285       0.04      1.00      1.00      0.08      1.00      1.00         1\n",
      "-0.16666666666666666       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                -0.2       0.00      0.00      0.98      0.00      0.00      0.00         9\n",
      "               -0.25       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " -0.3333333333333333       0.00      0.00      0.98      0.00      0.00      0.00        26\n",
      "-0.33333333333333337       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "-0.42857142857142855       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                -0.5       0.00      0.00      0.99      0.00      0.00      0.00         3\n",
      "                -0.6       0.00      0.00      0.97      0.00      0.00      0.00         1\n",
      " -0.6666666666666666       0.10      1.00      1.00      0.18      1.00      1.00         1\n",
      "                  -1       0.10      0.11      0.98      0.10      0.33      0.10       101\n",
      "                   0       0.31      0.02      0.99      0.04      0.14      0.02       695\n",
      " 0.14285714285714285       0.12      0.50      0.99      0.20      0.70      0.47        20\n",
      " 0.16666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "                 0.2       0.00      0.00      0.99      0.00      0.00      0.00         9\n",
      "                0.25       0.01      0.33      0.97      0.02      0.57      0.30         6\n",
      "  0.3333333333333333       0.03      0.03      0.98      0.03      0.16      0.02       117\n",
      " 0.33333333333333337       0.02      1.00      0.99      0.04      1.00      0.99         1\n",
      " 0.41666666666666663       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      " 0.42857142857142855       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " 0.45454545454545453       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "                 0.5       0.06      0.12      0.98      0.08      0.34      0.11        66\n",
      "                 0.6       0.00      0.62      0.69      0.01      0.66      0.43         8\n",
      "  0.6666666666666666       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "  0.7142857142857143       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                0.75       0.04      1.00      0.99      0.07      0.99      0.99         2\n",
      "                   1       0.94      0.43      0.89      0.59      0.62      0.37      4248\n",
      "\n",
      "         avg / total       0.80      0.36      0.91      0.48      0.53      0.30      5314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2b33ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'mean_custom_score': 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2064b554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6787b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062388591800356503"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521afc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    2,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    4,    2,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    4,    8,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    3,    7,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    1,    0,    0,    0],\n",
       "       [   0,    0,    0,    9,    0,   22,   17,    0,    0,    0,    0,\n",
       "           0,    0,    1,    1,    0,    0,    0,    0,    3,    3,    0,\n",
       "           0,   26,   11,    8,    0],\n",
       "       [   0,    1,    0,   68,    0,   76,   88,    0,    0,    5,    0,\n",
       "           0,    1,   14,    0,    4,    0,    0,    2,   18,   32,    7,\n",
       "           0,  220,  125,   34,    0],\n",
       "       [   0,    0,    0,    1,    0,    5,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    4,\n",
       "           0,    7,    1,    2,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    3,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,    0,    0],\n",
       "       [   0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "           0,    1,    1,    0,    0],\n",
       "       [   0,    1,    0,    1,    0,    4,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    2,    1,   19,    0,\n",
       "           0,   46,   40,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    4,    0,    4,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    1,    0,    0,    0,    0,   12,    4,\n",
       "           0,   23,   16,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    4,    2,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,    0],\n",
       "       [   0,    0,    0,  480,    0,   45,   53,    1,    0,    2,    0,\n",
       "           0,    0,    7,    3,    4,    0,    0,    6,  184,  641,    6,\n",
       "           6, 1671, 1113,   26,    0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ece8973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "-0.14285714285714285       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "-0.16666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "                -0.2       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "               -0.25       0.00      0.00      0.89      0.00      0.00      0.00         0\n",
      " -0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00        26\n",
      "-0.33333333333333337       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "-0.42857142857142855       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "                -0.5       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "                -0.6       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      " -0.6666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "                  -1       0.00      0.00      1.00      0.00      0.00      0.00       101\n",
      "                   0       0.00      0.00      1.00      0.00      0.00      0.00       695\n",
      " 0.14285714285714285       0.00      0.00      1.00      0.00      0.00      0.00        20\n",
      " 0.16666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "                 0.2       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "                0.25       0.00      0.00      1.00      0.00      0.00      0.00         6\n",
      "  0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00       117\n",
      " 0.33333333333333337       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      " 0.41666666666666663       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " 0.42857142857142855       0.00      0.00      0.96      0.00      0.00      0.00         0\n",
      " 0.45454545454545453       0.00      0.00      0.87      0.00      0.00      0.00         0\n",
      "                 0.5       0.18      0.06      1.00      0.09      0.25      0.05        66\n",
      "                 0.6       0.00      0.00      1.00      0.00      0.00      0.00         8\n",
      "  0.6666666666666666       0.00      0.00      0.62      0.00      0.00      0.00         0\n",
      "  0.7142857142857143       0.00      0.00      0.75      0.00      0.00      0.00         0\n",
      "                0.75       0.03      1.00      0.99      0.05      0.99      0.99         2\n",
      "                   1       0.00      0.00      1.00      0.00      0.00      0.00      4248\n",
      "\n",
      "         avg / total       0.00      0.00      1.00      0.00      0.00      0.00      5314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a82f00f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21820/1699390683.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msmote_enn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote_enn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmote_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menn_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    734\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m             )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce2efe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fe9eb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062388591800356503"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08b2a0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    2,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    4,    2,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    4,    8,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    3,    7,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    1,    0,    0,    0],\n",
       "       [   0,    0,    0,    9,    0,   22,   17,    0,    0,    0,    0,\n",
       "           0,    0,    1,    1,    0,    0,    0,    0,    3,    3,    0,\n",
       "           0,   26,   11,    8,    0],\n",
       "       [   0,    1,    0,   68,    0,   76,   88,    0,    0,    5,    0,\n",
       "           0,    1,   14,    0,    4,    0,    0,    2,   18,   32,    7,\n",
       "           0,  220,  125,   34,    0],\n",
       "       [   0,    0,    0,    1,    0,    5,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    4,\n",
       "           0,    7,    1,    2,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    3,    3,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,    0,    0],\n",
       "       [   0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "           0,    1,    1,    0,    0],\n",
       "       [   0,    1,    0,    1,    0,    4,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    2,    1,   19,    0,\n",
       "           0,   46,   40,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    4,    0,    4,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    1,    0,    0,    0,    0,   12,    4,\n",
       "           0,   23,   16,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    4,    2,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,    0],\n",
       "       [   0,    0,    0,  480,    0,   45,   53,    1,    0,    2,    0,\n",
       "           0,    0,    7,    3,    4,    0,    0,    6,  184,  641,    6,\n",
       "           6, 1671, 1113,   26,    0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d59a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "-0.14285714285714285       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "-0.16666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "                -0.2       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "               -0.25       0.00      0.00      0.89      0.00      0.00      0.00         0\n",
      " -0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00        26\n",
      "-0.33333333333333337       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "-0.42857142857142855       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "                -0.5       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "                -0.6       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      " -0.6666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "                  -1       0.00      0.00      1.00      0.00      0.00      0.00       101\n",
      "                   0       0.00      0.00      1.00      0.00      0.00      0.00       695\n",
      " 0.14285714285714285       0.00      0.00      1.00      0.00      0.00      0.00        20\n",
      " 0.16666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "                 0.2       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "                0.25       0.00      0.00      1.00      0.00      0.00      0.00         6\n",
      "  0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00       117\n",
      " 0.33333333333333337       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      " 0.41666666666666663       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " 0.42857142857142855       0.00      0.00      0.96      0.00      0.00      0.00         0\n",
      " 0.45454545454545453       0.00      0.00      0.87      0.00      0.00      0.00         0\n",
      "                 0.5       0.18      0.06      1.00      0.09      0.25      0.05        66\n",
      "                 0.6       0.00      0.00      1.00      0.00      0.00      0.00         8\n",
      "  0.6666666666666666       0.00      0.00      0.62      0.00      0.00      0.00         0\n",
      "  0.7142857142857143       0.00      0.00      0.75      0.00      0.00      0.00         0\n",
      "                0.75       0.03      1.00      0.99      0.05      0.99      0.99         2\n",
      "                   1       0.00      0.00      1.00      0.00      0.00      0.00      4248\n",
      "\n",
      "         avg / total       0.00      0.00      1.00      0.00      0.00      0.00      5314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15f13068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "brf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc2bf3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4422128553266853"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = brf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "686fc760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    2,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    1,    3,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    5,    0,    2,    1,    1,    2,    0,    6,    0,    0,\n",
       "           0,    0,    2,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    6,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    2,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    8,    1,   11,    2,    5,   14,    1,   16,    3,    4,\n",
       "           0,    0,   10,    9,    0,    0,    5,    5,    0,    0,    0,\n",
       "           0,    0,    6,    0,    0],\n",
       "       [   2,   50,   45,   38,   15,   39,   56,   16,  145,    1,   32,\n",
       "           1,    4,   26,   11,   16,    0,   59,    6,   21,    9,    0,\n",
       "          28,    2,   43,    0,   30],\n",
       "       [   0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    8,    0,    0,    7,    0,    0,    0,    0,    1,    0,\n",
       "           0,    3,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    2,    2,    0,    1,    0,    0,\n",
       "           0,    0,    1,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    5,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   1,    1,    0,    0,    0,    2,    3,    2,   10,    1,    1,\n",
       "           0,    0,    0,    1,    1,    0,    8,    4,    6,    1,    0,\n",
       "          68,    0,    2,    0,    5],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   1,    2,    0,    1,    0,    1,    1,    0,    4,    0,    0,\n",
       "           0,    0,    0,    1,    0,    0,    1,    1,    1,    0,    8,\n",
       "          41,    1,    2,    0,    0],\n",
       "       [   0,    0,    1,    0,    0,    1,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           5,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,    0],\n",
       "       [   0,   35,  420,   20,    9,   11,   53,    7,  107,    0,   12,\n",
       "           1,   94,   11,   15,   87,    3,   36,    6,  916,   40,   45,\n",
       "        1754,    2,   32,    0,  532]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3119340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "-0.14285714285714285       0.17      1.00      1.00      0.29      1.00      1.00         1\n",
      "-0.16666666666666666       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "                -0.2       0.00      0.22      0.91      0.01      0.45      0.19         9\n",
      "               -0.25       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      " -0.3333333333333333       0.04      0.04      1.00      0.04      0.20      0.03        26\n",
      "-0.33333333333333337       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "-0.42857142857142855       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "                -0.5       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "                -0.6       0.00      1.00      0.95      0.01      0.97      0.95         1\n",
      " -0.6666666666666666       0.17      1.00      1.00      0.29      1.00      1.00         1\n",
      "                  -1       0.08      0.04      0.99      0.05      0.20      0.04       101\n",
      "                   0       0.50      0.00      1.00      0.00      0.04      0.00       695\n",
      " 0.14285714285714285       0.08      0.40      0.98      0.13      0.63      0.37        20\n",
      " 0.16666666666666666       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                 0.2       0.03      0.11      0.99      0.04      0.33      0.10         9\n",
      "                0.25       0.04      0.83      0.98      0.08      0.90      0.80         6\n",
      "  0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00       117\n",
      " 0.33333333333333337       0.01      1.00      0.98      0.02      0.99      0.98         1\n",
      " 0.41666666666666663       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " 0.42857142857142855       0.00      0.00      0.82      0.00      0.00      0.00         0\n",
      " 0.45454545454545453       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                 0.5       0.15      0.12      0.99      0.13      0.35      0.11        66\n",
      "                 0.6       0.00      0.62      0.64      0.01      0.63      0.40         8\n",
      "  0.6666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "  0.7142857142857143       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "                0.75       1.00      1.00      1.00      1.00      1.00      1.00         2\n",
      "                   1       0.94      0.13      0.97      0.22      0.35      0.11      4248\n",
      "\n",
      "         avg / total       0.82      0.11      0.97      0.18      0.30      0.10      5314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d98f0eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean_t_neg_score</td>\n",
       "      <td>0.120976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_tgt_comp_score</td>\n",
       "      <td>0.119459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_t_pos_score</td>\n",
       "      <td>0.115862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overall_sent_comp</td>\n",
       "      <td>0.110528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean_tgt_pos_score</td>\n",
       "      <td>0.109769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overall_sent_pos</td>\n",
       "      <td>0.107346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>overall_sent_neg</td>\n",
       "      <td>0.099340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_t_comp_score</td>\n",
       "      <td>0.084648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean_tgt_neg_score</td>\n",
       "      <td>0.077475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ticker</td>\n",
       "      <td>0.054596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "6     mean_t_neg_score    0.120976\n",
       "7  mean_tgt_comp_score    0.119459\n",
       "5     mean_t_pos_score    0.115862\n",
       "1    overall_sent_comp    0.110528\n",
       "8   mean_tgt_pos_score    0.109769\n",
       "2     overall_sent_pos    0.107346\n",
       "3     overall_sent_neg    0.099340\n",
       "4    mean_t_comp_score    0.084648\n",
       "9   mean_tgt_neg_score    0.077475\n",
       "0               ticker    0.054596"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = brf.feature_importances_\n",
    "cols = X.columns\n",
    "feature_importances_df = pd.DataFrame({'feature':cols, 'importance': importances})\n",
    "feature_importances_df.head()\n",
    "feature_importances_df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5248f771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec = EasyEnsembleClassifier(n_estimators=100, random_state=1)\n",
    "eec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ec6f443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29282663809750864"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = eec.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f867e6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    1,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    2,    0,    0,    3,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    6,    0,    6,    0,    1,    3,    1,    1,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    4,    0,    0,\n",
       "           0,    0,    3,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    1,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,   22,    0,   20,    0,    4,    9,    3,    7,    0,    1,\n",
       "           0,    0,   10,    0,    0,    0,   11,    0,    7,    0,    0,\n",
       "           0,    1,    6,    0,    0],\n",
       "       [   2,  117,    0,  103,    0,   10,   34,   20,   75,    1,   25,\n",
       "           0,   23,   28,    0,   13,    0,   64,    0,   60,    9,    0,\n",
       "          22,    6,   73,    0,   10],\n",
       "       [   0,    7,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    7,    0,    0,    5,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    4,    0,    1,    0,    1,    0,    0,    1,    0,    0,\n",
       "           0,    0,    1,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    5,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,    0,    0],\n",
       "       [   0,    5,    0,    6,    0,    0,    3,    0,    5,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    5,    3,    8,    0,    0,\n",
       "          69,    0,   13,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    3,    0,    5,    0,    1,    0,    1,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    2,    0,    8,\n",
       "          41,    0,    4,    0,    0],\n",
       "       [   0,    1,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
       "           5,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    2,    0],\n",
       "       [   4,  103,    0,   99,    0,    2,   20,   11,   50,    0,   12,\n",
       "           0,  679,    9,    0,    4,    0,   33,    0,  973,   39,    0,\n",
       "        1844,    3,  199,    0,  164]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df216b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "-0.14285714285714285       0.14      1.00      1.00      0.25      1.00      1.00         1\n",
      "-0.16666666666666666       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
      "                -0.2       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "               -0.25       0.00      0.00      0.95      0.00      0.00      0.00         0\n",
      " -0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00        26\n",
      "-0.33333333333333337       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "-0.42857142857142855       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                -0.5       0.00      0.00      0.99      0.00      0.00      0.00         3\n",
      "                -0.6       0.00      0.00      0.97      0.00      0.00      0.00         1\n",
      " -0.6666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "                  -1       0.03      0.01      0.99      0.01      0.10      0.01       101\n",
      "                   0       0.00      0.00      1.00      0.00      0.00      0.00       695\n",
      " 0.14285714285714285       0.01      0.35      0.87      0.02      0.55      0.29        20\n",
      " 0.16666666666666666       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                 0.2       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "                0.25       0.17      0.83      1.00      0.28      0.91      0.82         6\n",
      "  0.3333333333333333       0.00      0.00      1.00      0.00      0.00      0.00       117\n",
      " 0.33333333333333337       0.01      1.00      0.98      0.02      0.99      0.98         1\n",
      " 0.41666666666666663       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      " 0.42857142857142855       0.00      0.00      0.80      0.00      0.00      0.00         0\n",
      " 0.45454545454545453       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "                 0.5       1.00      0.12      1.00      0.22      0.35      0.11        66\n",
      "                 0.6       0.00      0.62      0.63      0.01      0.63      0.39         8\n",
      "  0.6666666666666666       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "  0.7142857142857143       0.00      0.00      0.94      0.00      0.00      0.00         0\n",
      "                0.75       1.00      1.00      1.00      1.00      1.00      1.00         2\n",
      "                   1       0.94      0.04      0.99      0.07      0.20      0.03      4248\n",
      "\n",
      "         avg / total       0.77      0.04      0.99      0.06      0.17      0.03      5314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c9cf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34d8743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Well these are the stocks i like and in this specific order, unless it''s a Monday following a 4-day trading week, if the 12th of the month falls on a Thursday or it''s after-hours market in which case you reverse all the ticker symbols and then those are the stocks I like:\\n\\nMGM, MCHP, MU, MSFT, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS MMM, ABT, ABBV, ABMD,  AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB.\\n\\nEdit: i am not a financial professional...i don''t lose enough money to be considered one yet    1668\n",
       "I copy pasted those stock tickers and posted. Here’s some more to fuck em up.\\n\\nstocks I like - \\nMMM, ABT, ABBV, ABMD, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MGM, MCHP, MU, MSFT, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS                                                                                                                                                                                                                                                                                         1485\n",
       "MMM, ABT, ABBV, ABMD, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MGM, MCHP, MU, MSFT, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS                                                                                                                                                                                                                                                                                                                                                                                            1320\n",
       "I copy pasted those stock tickers and posted. Here’s some more to fuck em up.\\n\\nstocks I like - MMM, ABT, ABBV, ABMD, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MGM, MCHP, MU, MSFT, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS                                                                                                                                                                                                                                                                                           1276\n",
       "MGM, MCHP, MU, MSFT, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS MMM, ABT, ABBV, ABMD, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB                                                                                                                                                                                                                                                                                                                                                                                              708\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ... \n",
       "Cathy liquidated her SPCE lol. Picking  up WKHS too, time for WKHS to moon                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "I loaded up on $55 calls. Easy money imo, Singh traded Spce since pre merger so easy to tell. Also holding 1k shares at $10.50 for a long, long time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       "I'm debating dropping my SPCE bags at a 40% loss....kinda want to hold out for some hype for the May test flight that hopefully happens...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "Well yeah they don't start trading til 9 lol                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
       "Guys tesla 200 puts for next week and sq 30 puts for next week I promise EASIEST GAINS EVER AND JUST HOLD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
       "Name: body, Length: 74380, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "comment_counts = sentiments_df[\"body\"].value_counts()\n",
    "print(len(comment_counts))\n",
    "comment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dac1702c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of comments\n",
    "comment_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bc11411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Well these are the stocks i like and in this specific order, unless it''s a Monday following a 4-day trading week, if the 12th of the month falls on a Thursday or it''s after-hours market in which case you reverse all the ticker symbols and then those are the stocks I like:\\n\\nMGM, MCHP, MU, MSFT, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS MMM, ABT, ABBV, ABMD,  AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB.\\n\\nEdit: i am not a financial professional...i don''t lose enough money to be considered one yet    1668\n",
       "I copy pasted those stock tickers and posted. Here’s some more to fuck em up.\\n\\nstocks I like - \\nMMM, ABT, ABBV, ABMD, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MGM, MCHP, MU, MSFT, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS                                                                                                                                                                                                                                                                                         1485\n",
       "MMM, ABT, ABBV, ABMD, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MGM, MCHP, MU, MSFT, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS                                                                                                                                                                                                                                                                                                                                                                                            1320\n",
       "I copy pasted those stock tickers and posted. Here’s some more to fuck em up.\\n\\nstocks I like - MMM, ABT, ABBV, ABMD, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MGM, MCHP, MU, MSFT, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS                                                                                                                                                                                                                                                                                           1276\n",
       "MGM, MCHP, MU, MSFT, SWKS, SLG, SNA, SO, LUV, SWK, SBUX, STT, STE, SYK, SIVB, SYF, SNPS, SYY, TMUS, TROW, TTWO, TPR, TGT, TEL, FTI, TFX, TXN, TXT, TMO, TIF, TJX, TSCO, TDG, TRV, TFC, TWTR, TSN, UDR, ULTA, USB, UAA, UA, UNP, UAL, UNH, UPS, URI, UTX, UHS, UNM, VFC, VLO, VAR, VTR, VRSN, VRSK, VZ, VRTX, VIAC, V, VNO, VMC, WRB, WAB, WMT, WBA, DIS, WM, WAT, WEC, WFC, WELL, WDC, WU, WRK, WY, WHR, WMB, WLTW, WYNN, XEL, XRX, XLNX, XYL, YUM, ZBRA, ZBH, ZION, ZTS MMM, ABT, ABBV, ABMD, AVY, BKR, BLL, BAC, BK, BAX, BDX, BRK.B, BBY, BIIB, BLK, BA, BKNG, BWA, BXP, BSX, BMY, AVGO, BR, BF.B, CHRW, COG, CDNS, CPB, COF, CPRI, CAH, KMX, CCL, CAT, CBOE, CBRE, CDW, CE, CNC, CNP, CTL, CERN, CF, SCHW, CHTR, CVX, CMG, CB, CHD, CI, XEC, CINF, CTAS, CSCO, C, CFG, CTXS, CLX, CME, CMS, KO, CTSH, CL, CMCSA, CMA, CAG, CXO, COP, ED, STZ, COO, CPRT, GLW, CTVA, COST, COTY, CCI, CSX, CMI, CVS, DHI, DHR, DRI, DVA, DE, DAL, XRAY, DVN, FANG, DLR, DFS, DISCA, DISCK, DISH, DG, DLTR, D, DOV, DOW, DTE, DUK, DRE, DD, DXC, ETFC, EMN, ETN, EBAY, ECL, EIX, EW, EA, EMR, ETR, EOG, EFX, EQIX, EQR, ESS, EL, EVRG, ES, RE, EXC, EXPE, EXPD, EXR, XOM, FFIV, FB, FAST, FRT, FDX, FIS, FITB, FE, FRC, FISV, FLT, FLIR, FLS, FMC, F, FTNT, FTV, FBHS, FOXA, FOX, BEN, FCX, GPS, GRMN, IT, GD, GE, GIS, GM, GPC, GILD, GL, GPN, GS, GWW, HRB, HAL, HBI, HOG, HIG, HAS, HCA, PEAK, HP, HSIC, HSY, HES, HPE, HLT, HFC, HOLX, HD, HON, HRL, HST, HPQ, HUM, HBAN, HII, IEX, IDXX, INFO, ITW, ILMN, IR, INTC, ICE, IBM, INCY, IP, IPG, IFF, INTU, ISRG, IVZ, IPGP, IQV, IRM, JKHY, J, JBHT, SJM, JNJ, JCI, JPM, JNPR, KSU, K, KEY, KEYS, KMB, KIM, KMI, KLAC, KSS, KHC, KR, LB, LHX, LH, LRCX, LW, LVS, LEG, LDOS, LEN, LLY, LNC, LIN, LYV, LKQ, LMT, L, LOW, LYB, MTB, M, MRO, MPC, MKTX, MAR, MMC, MLM, MAS, MA, MKC, MXIM, MCD, MCK, MDT, MRK, MET, MTD, MAA, MHK, TAP, MDLZ, MNST, MCO, MS, MOS, MSI, MSCI, MYL, NDAQ, NOV, NTAP, NFLX, NWL, NEM, NWSA, NWS, NEE, NLSN, NKE, NI, NBL, JWN, NSC, NTRS, NOC, NLOK, NCLH, NRG, NUE, NVDA, NVR, ORLY, OXY, ODFL, OMC, OKE, ORCL, PCAR, PKG, PH, PAYX, PAYC, PYPL, PNR, PBCT, PEP, PKI, PRGO, PFE, PM, PSX, PNW, PXD, PNC, PPG, PPL, PFG, PG, PGR, PLD, PRU, PEG, PSA, PHM, PVH, QRVO, PWR, QCOM, DGX, RL, RJF, RTN, O, REG, REGN, RF, RSG, RMD, RHI, ROK, ROL, ROP, ROST, RCL, SPGI, CRM, SBAC, SLB, STX, SEE, SRE, NOW, SHW, SPG, ACN, ATVI, ADBE, AMD, AAP, AES, AFL, A, APD, AKAM, ALK, ALB, ARE, ALXN, ALGN, ALLE, AGN, ADS, LNT, ALL, GOOGL, GOOG, MO, AMZN, AMCR, AEE, AAL, AEP, AXP, AIG, AMT, AWK, AMP, ABC, AME, AMGN, APH, ADI, ANSS, ANTM, AON, AOS, APA, AIV, AAPL, AMAT, APTV, ADM, ARNC, ANET, AJG, AIZ, ATO, T, ADSK, ADP, AZO, AVB                                                                                                                                                                                                                                                                                                                                                                                              708\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ... \n",
       "Cathy liquidated her SPCE lol. Picking  up WKHS too, time for WKHS to moon                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "I loaded up on $55 calls. Easy money imo, Singh traded Spce since pre merger so easy to tell. Also holding 1k shares at $10.50 for a long, long time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       "I'm debating dropping my SPCE bags at a 40% loss....kinda want to hold out for some hype for the May test flight that hopefully happens...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
       "Well yeah they don't start trading til 9 lol                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
       "Guys tesla 200 puts for next week and sq 30 puts for next week I promise EASIEST GAINS EVER AND JUST HOLD                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
       "Name: body, Length: 74380, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "#replace_application = list(application_counts[application_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "#for app in replace_application:\n",
    "    #application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "sentiments_df.body.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4585a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'CLASSIFICATION'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21820/2502650400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Look at CLASSIFICATION value counts for binning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiments_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASSIFICATION\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'CLASSIFICATION'"
     ]
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_counts = sentiments_df.CLASSIFICATION.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35d874a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21820/4284942064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize the value counts of CLASSIFICATION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclass_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'class_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize the value counts of CLASSIFICATION\n",
    "class_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d79da535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment_id',\n",
       " 'ticker',\n",
       " 'date',\n",
       " 'username',\n",
       " 'subreddit',\n",
       " 'body',\n",
       " 'overall_sent_comp',\n",
       " 'overall_sent_pos',\n",
       " 'overall_sent_neg',\n",
       " 'mean_t_comp_score',\n",
       " 'mean_t_pos_score',\n",
       " 'mean_t_neg_score',\n",
       " 'mean_tgt_comp_score',\n",
       " 'mean_tgt_pos_score',\n",
       " 'mean_tgt_neg_score',\n",
       " 'verb_tense',\n",
       " 'mean_custom_score']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "comments_cat = sentiments_df.dtypes[sentiments_df.dtypes == \"object\"].index.tolist()\n",
    "comments_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e922b80",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 160. GiB for an array with shape (125485, 171624) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21820/1625931196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Fit and transform the OneHotEncoder using the categorical variable list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mencode_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiments_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcomments_cat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Add the encoded variable names to the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \"\"\"\n\u001b[0;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    511\u001b[0m                                 dtype=self.dtype)\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 160. GiB for an array with shape (125485, 171624) and data type float64"
     ]
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(sentiments_df[comments_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(sentiments_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4453b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encode_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21820/3329021071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Merge one-hot encoded features and drop the originals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msentiments_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiments_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msentiments_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiments_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments_cat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msentiments_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encode_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "sentiments_df = sentiments_df.merge(encode_df,left_index=True, right_index=True)\n",
    "sentiments_df = sentiments_df.drop(comments_cat,1)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e99638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = comments_df[\"Positive\"].values\n",
    "X = comments_df.drop([\"Negative\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6794b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  80\n",
    "hidden_nodes_layer2 = 30\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208606af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8f1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

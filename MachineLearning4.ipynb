{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c972e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "# from config import password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9640e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474da3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_sent_comp</th>\n",
       "      <th>overall_sent_pos</th>\n",
       "      <th>overall_sent_neg</th>\n",
       "      <th>mean_t_comp_score</th>\n",
       "      <th>mean_t_pos_score</th>\n",
       "      <th>mean_t_neg_score</th>\n",
       "      <th>mean_tgt_comp_score</th>\n",
       "      <th>mean_tgt_pos_score</th>\n",
       "      <th>mean_tgt_neg_score</th>\n",
       "      <th>verb_tense</th>\n",
       "      <th>...</th>\n",
       "      <th>CloseOver60</th>\n",
       "      <th>VolumeOver60</th>\n",
       "      <th>CloseOver90</th>\n",
       "      <th>VolumeOver90</th>\n",
       "      <th>Co30_d</th>\n",
       "      <th>Co60_d</th>\n",
       "      <th>Co90_d</th>\n",
       "      <th>Vo30_d</th>\n",
       "      <th>Vo60_d</th>\n",
       "      <th>Vo90_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.08706666666666667</td>\n",
       "      <td>0.11783333333333333</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>-0.5818</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.157</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>127.534833</td>\n",
       "      <td>8.716522e+06</td>\n",
       "      <td>135.033889</td>\n",
       "      <td>10756920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.16466666666666666</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>127.534833</td>\n",
       "      <td>8.716522e+06</td>\n",
       "      <td>135.033889</td>\n",
       "      <td>10756920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.08706666666666667</td>\n",
       "      <td>0.11783333333333333</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>-0.5818</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.157</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>127.534833</td>\n",
       "      <td>8.716522e+06</td>\n",
       "      <td>135.033889</td>\n",
       "      <td>10756920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.08706666666666667</td>\n",
       "      <td>0.11783333333333333</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>-0.5818</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.157</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>127.534833</td>\n",
       "      <td>8.716522e+06</td>\n",
       "      <td>135.033889</td>\n",
       "      <td>10756920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>present</td>\n",
       "      <td>...</td>\n",
       "      <td>127.534833</td>\n",
       "      <td>8.716522e+06</td>\n",
       "      <td>135.033889</td>\n",
       "      <td>10756920.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  overall_sent_comp overall_sent_pos overall_sent_neg    mean_t_comp_score  \\\n",
       "0            0.5078            0.102            0.075  0.08706666666666667   \n",
       "1            0.8658            0.245            0.036               0.1761   \n",
       "2            0.5078            0.102            0.075  0.08706666666666667   \n",
       "3            0.5078            0.102            0.075  0.08706666666666667   \n",
       "4           -0.5994                0            0.438              -0.5994   \n",
       "\n",
       "      mean_t_pos_score mean_t_neg_score mean_tgt_comp_score  \\\n",
       "0  0.11783333333333333           0.0485             -0.5818   \n",
       "1  0.16466666666666666            0.074              0.7783   \n",
       "2  0.11783333333333333           0.0485             -0.5818   \n",
       "3  0.11783333333333333           0.0485             -0.5818   \n",
       "4                    0            0.438             -0.5994   \n",
       "\n",
       "  mean_tgt_pos_score mean_tgt_neg_score verb_tense  ... CloseOver60  \\\n",
       "0              0.084              0.157    present  ...  127.534833   \n",
       "1              0.494                  0    present  ...  127.534833   \n",
       "2              0.084              0.157    present  ...  127.534833   \n",
       "3              0.084              0.157    present  ...  127.534833   \n",
       "4                  0              0.438    present  ...  127.534833   \n",
       "\n",
       "   VolumeOver60  CloseOver90  VolumeOver90  Co30_d  Co60_d  Co90_d  Vo30_d  \\\n",
       "0  8.716522e+06   135.033889    10756920.0       0      -1       1      -1   \n",
       "1  8.716522e+06   135.033889    10756920.0       0      -1       1      -1   \n",
       "2  8.716522e+06   135.033889    10756920.0       0      -1       1      -1   \n",
       "3  8.716522e+06   135.033889    10756920.0       0      -1       1      -1   \n",
       "4  8.716522e+06   135.033889    10756920.0       0      -1       1      -1   \n",
       "\n",
       "   Vo60_d  Vo90_d  \n",
       "0      -1      -1  \n",
       "1      -1      -1  \n",
       "2      -1      -1  \n",
       "3      -1      -1  \n",
       "4      -1      -1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_data_to_load = \"cleaned_sentiment.csv\"\n",
    "sentiments_df = pd.read_csv(sentiments_data_to_load, on_bad_lines='skip')\n",
    "sentiments_df = sentiments_df.drop(['Unnamed: 0','date','ticker'],axis=1)\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e479f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df = sentiments_df.drop([\"overall_sent_comp\", \"overall_sent_pos\",\n",
    "    \"overall_sent_neg\", \"mean_t_comp_score\", \"mean_t_pos_score\", \"mean_t_neg_score\", \"mean_tgt_comp_score\",\n",
    "    \"mean_tgt_pos_score\", \"mean_tgt_neg_score\", \"verb_tense\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0d8edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2018 0:00</td>\n",
       "      <td>15.691743</td>\n",
       "      <td>15.980067</td>\n",
       "      <td>15.534477</td>\n",
       "      <td>15.953856</td>\n",
       "      <td>2832700</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/3/2018 0:00</td>\n",
       "      <td>15.980067</td>\n",
       "      <td>16.049963</td>\n",
       "      <td>15.656795</td>\n",
       "      <td>15.901433</td>\n",
       "      <td>3789200</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/4/2018 0:00</td>\n",
       "      <td>15.901433</td>\n",
       "      <td>16.058699</td>\n",
       "      <td>15.691743</td>\n",
       "      <td>16.006277</td>\n",
       "      <td>2781300</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/5/2018 0:00</td>\n",
       "      <td>16.058702</td>\n",
       "      <td>16.364499</td>\n",
       "      <td>15.918909</td>\n",
       "      <td>16.320814</td>\n",
       "      <td>3019000</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/2018 0:00</td>\n",
       "      <td>16.425656</td>\n",
       "      <td>16.949880</td>\n",
       "      <td>16.425656</td>\n",
       "      <td>16.801350</td>\n",
       "      <td>3668400</td>\n",
       "      <td>GME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       open       high        low      close   volume ticker\n",
       "0  1/2/2018 0:00  15.691743  15.980067  15.534477  15.953856  2832700    GME\n",
       "1  1/3/2018 0:00  15.980067  16.049963  15.656795  15.901433  3789200    GME\n",
       "2  1/4/2018 0:00  15.901433  16.058699  15.691743  16.006277  2781300    GME\n",
       "3  1/5/2018 0:00  16.058702  16.364499  15.918909  16.320814  3019000    GME\n",
       "4  1/8/2018 0:00  16.425656  16.949880  16.425656  16.801350  3668400    GME"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data_to_load = \"stock_history.csv\"\n",
    "history_df = pd.read_csv(history_data_to_load, low_memory=False)\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfe29f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.691743</td>\n",
       "      <td>15.980067</td>\n",
       "      <td>15.534477</td>\n",
       "      <td>15.953856</td>\n",
       "      <td>2832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.980067</td>\n",
       "      <td>16.049963</td>\n",
       "      <td>15.656795</td>\n",
       "      <td>15.901433</td>\n",
       "      <td>3789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.901433</td>\n",
       "      <td>16.058699</td>\n",
       "      <td>15.691743</td>\n",
       "      <td>16.006277</td>\n",
       "      <td>2781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.058702</td>\n",
       "      <td>16.364499</td>\n",
       "      <td>15.918909</td>\n",
       "      <td>16.320814</td>\n",
       "      <td>3019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.425656</td>\n",
       "      <td>16.949880</td>\n",
       "      <td>16.425656</td>\n",
       "      <td>16.801350</td>\n",
       "      <td>3668400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        open       high        low      close   volume\n",
       "0  15.691743  15.980067  15.534477  15.953856  2832700\n",
       "1  15.980067  16.049963  15.656795  15.901433  3789200\n",
       "2  15.901433  16.058699  15.691743  16.006277  2781300\n",
       "3  16.058702  16.364499  15.918909  16.320814  3019000\n",
       "4  16.425656  16.949880  16.425656  16.801350  3668400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df['date'] = pd.to_datetime(history_df['date'])\n",
    "history_df = history_df.drop(['date','ticker'],axis=1)\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf8cf297",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'volume'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26040/674002277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Combine the data into a single dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msentiments_history_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiments_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"volume\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msentiments_history_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1107\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1110\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'volume'"
     ]
    }
   ],
   "source": [
    "# Combine the data into a single dataset.\n",
    "sentiments_history_df = pd.merge(sentiments_df, history_df, on=[\"volume\"])\n",
    "sentiments_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_history_df = sentiments_df.loc[sentiments_df[\"ticker\"].isin (ticker_list)]\n",
    "\n",
    "sentiments_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec80d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_history_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sentiments_history_df.drop(columns=[\"mean_custom_score\"])\n",
    "X.shape\n",
    "y = sentiments_history_df.loc[:, [\"mean_custom_score\"]].copy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values\n",
    "X['ticker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79142ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_feature(array):\n",
    "    \"\"\" Encode a categorical array into a number array\n",
    "    \n",
    "    :param array: array to be encoded\n",
    "    :return: numerical array\n",
    "    \"\"\"\n",
    "  \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(array)\n",
    "    return encoder.transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2190d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"ticker\"] = encode_feature(X[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ticker'].value_counts()\n",
    "\n",
    "# MSFT    4\n",
    "# AAPL    0\n",
    "# AMZN    1\n",
    "# FB      2\n",
    "# GOOG    3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists\n",
    "sentiments_cat = sentiments_history_df.dtypes[sentiments_history_df.dtypes == \"object\"].index.tolist()\n",
    "sentiments_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ec457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036400d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739018bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a65832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b33ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6787b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521afc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2efe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f13068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "brf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bf3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = brf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686fc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = brf.feature_importances_\n",
    "cols = X.columns\n",
    "feature_importances_df = pd.DataFrame({'feature':cols, 'importance': importances})\n",
    "feature_importances_df.head()\n",
    "feature_importances_df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec = EasyEnsembleClassifier(n_estimators=100, random_state=1)\n",
    "eec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = eec.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df216b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "comment_counts = sentiments_df[\"body\"].value_counts()\n",
    "print(len(comment_counts))\n",
    "comment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the value counts of comments\n",
    "comment_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc11411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "#replace_application = list(application_counts[application_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "#for app in replace_application:\n",
    "    #application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "sentiments_df.body.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4585a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_counts = sentiments_df.CLASSIFICATION.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d874a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the value counts of CLASSIFICATION\n",
    "class_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79da535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists\n",
    "comments_cat = sentiments_df.dtypes[sentiments_df.dtypes == \"object\"].index.tolist()\n",
    "comments_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e922b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(sentiments_df[comments_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(sentiments_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4453b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "sentiments_df = sentiments_df.merge(encode_df,left_index=True, right_index=True)\n",
    "sentiments_df = sentiments_df.drop(comments_cat,1)\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e99638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = comments_df[\"Positive\"].values\n",
    "X = comments_df.drop([\"Negative\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6794b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  80\n",
    "hidden_nodes_layer2 = 30\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208606af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8f1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
